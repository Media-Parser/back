# ğŸ“ app/routes/chat.py
from fastapi import APIRouter, HTTPException
from app.services.chat_service import save_chat_qa, get_chat_history, delete_chat_history
from app.models.chat_model import ChatSendRequest, ChatQA
from typing import List
import httpx
import os

AI_SERVER_URL = os.getenv("AI_SERVER_URL")

router = APIRouter(prefix="/chat", tags=["Chatbot"])

# ì§ˆë¬¸ ì €ì¥ (AI inference í›„ ê°’ ì…ë ¥)
@router.post("/send", response_model=ChatQA)
async def chat_send(req: ChatSendRequest):
    # ì‹¤ì œë¡œëŠ” AI ì„œë²„ì— req.message, req.article_content ë“± ì „ë‹¬
    # ì•„ë˜ì²˜ëŸ¼ AI inference ë¡œì§ ì—°ë™ (ì˜ˆì‹œ)
    ai_answer, ai_suggestion = await your_ai_inference(req.message, req.article_content)
    chat_qa = await save_chat_qa(req.doc_id, req.message, ai_answer, ai_suggestion)
    return chat_qa

# ë¬¸ì„œë³„ QA íˆìŠ¤í† ë¦¬
@router.get("/history/{doc_id}", response_model=List[ChatQA])
async def chat_history(doc_id: str):
    qas = await get_chat_history(doc_id)
    return qas

# ì „ì²´ ì‚­ì œ
@router.delete("/history/{doc_id}")
async def delete_history(doc_id: str):
    deleted = await delete_chat_history(doc_id)
    return {"deleted_count": deleted}

async def your_ai_inference(message, article_content):
    async with httpx.AsyncClient() as client:
        payload = {
            "message": message,
            "article_content": article_content
        }
        # AI inference ì„œë²„ë¡œ POST ìš”ì²­
        resp = await client.post(f"{AI_SERVER_URL}/chat/send", json=payload)
        resp.raise_for_status()
        data = resp.json()
        # AI ì‘ë‹µ í˜•íƒœì— ë§ì¶° ê°’ ì¶”ì¶œ (í‚¤ ì´ë¦„ì€ ì‹¤ì œ ì‘ë‹µ ì°¸ê³ )
        answer = data.get("chatbot_response") or data.get("article_content")
        suggestion = data.get("suggestion")
        return answer, suggestion
# service/node/04_retrieval/standard_retrieval_node.py
from datetime import datetime
from dotenv import load_dotenv
from langchain_core.documents import Document
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma

load_dotenv()

# --- ì„¤ì • ---
PERSIST_DIR = "chroma_db"
COLLECTION_NAME = "langchain"
embedding_function = OpenAIEmbeddings()

# --- ìƒíƒœ(State) ëª¨ë°© í´ë˜ìŠ¤ ---
class GraphState(dict):
    pass

# --- ë‚ ì§œ ë³€í™˜ í—¬í¼ í•¨ìˆ˜ ---
def date_to_int(date_str: str) -> int | None:
    """YYYY-MM-DD í˜•ì‹ì˜ ë¬¸ìì—´ì„ YYYYMMDD í˜•ì‹ì˜ ì •ìˆ˜ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    try:
        return int(datetime.strptime(date_str, "%Y-%m-%d").strftime("%Y%m%d"))
    except (ValueError, TypeError):
        return None

# --- ìµœì¢… ê²€ìƒ‰ ë…¸ë“œ í•¨ìˆ˜ ---
def standard_retrieval_node(state: GraphState) -> GraphState:
    """
    ë©”íƒ€ë°ì´í„° í•„í„°ë§ê³¼ í•¨ê»˜ ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ í¬í•¨í•˜ì—¬ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    """
    print("--- ë…¸ë“œ ì‹¤í–‰: standard_retrieval (ìœ ì‚¬ë„ ì ìˆ˜ í¬í•¨) ---")
    plan = state["plan"]
    rewritten_question = plan["rewritten_question"]
    
    vectorstore = Chroma(
        persist_directory=PERSIST_DIR,
        embedding_function=embedding_function,
        collection_name=COLLECTION_NAME
    )

    parameters = plan.get("parameters") or {}
    filters = plan.get("filters") or {}
    k = parameters.get("k", 10)

    filter_conditions = []

    # ë‚ ì§œ ë²”ìœ„ í•„í„°ë§ (date_int ì‚¬ìš©)
    start_date_int = date_to_int(filters.get("startdate"))
    if start_date_int is not None:
        filter_conditions.append({'date_int': {'$gte': start_date_int}})

    end_date_int = date_to_int(filters.get("enddate"))
    if end_date_int is not None:
        filter_conditions.append({'date_int': {'$lte': end_date_int}})
    
    # í† í”½ í•„í„°ë§
    topic_filter = filters.get("topic")
    if topic_filter:
        filter_conditions.append({'topic': {'$eq': topic_filter}})

    search_filter = {}
    if len(filter_conditions) > 1:
        search_filter = {"$and": filter_conditions}
    elif len(filter_conditions) == 1:
        search_filter = filter_conditions[0]

    print(f"ğŸ” ê²€ìƒ‰ í•„í„°: {search_filter}")
    
    # *** í•µì‹¬ ìˆ˜ì • ë¶€ë¶„: retriever.invoke ëŒ€ì‹  similarity_search_with_relevance_scores ì‚¬ìš© ***
    docs_with_scores = vectorstore.similarity_search_with_relevance_scores(
        query=rewritten_question,
        k=k,
        filter=search_filter
    )

    print(f"âœ… 'advanced' ì „ëµìœ¼ë¡œ {len(docs_with_scores)}ê°œì˜ ë¬¸ì„œë¥¼ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤.")
    # ë…¸ë“œì˜ ì¶œë ¥ ìƒíƒœ ì´ë¦„ë„ ëª…í™•í•˜ê²Œ ë³€ê²½
    return {"docs_with_scores": docs_with_scores}



# --- ì´ ë…¸ë“œë¥¼ ë‹¨ë…ìœ¼ë¡œ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ì½”ë“œ ---
if __name__ == '__main__':
    # 1. ì…ë ¥ ìƒíƒœ(State) ì •ì˜
    input_state = GraphState({
        "plan": {
            "strategy": "standard_retrieval",
            "rewritten_question": "ë¶€ë™ì‚° ì •ì±…",
            "filters": {
                "startdate": "2024-03-01",
                "enddate": "2024-03-31",
            },
            "parameters": {"k": 5}
        },
        "question": "",
        "original_question": ""
    })

    # 2. ë…¸ë“œ í•¨ìˆ˜ ì‹¤í–‰
    retrieval_result = standard_retrieval_node(input_state)

    # 3. ê²°ê³¼ í™•ì¸
    print("\n--- ë…¸ë“œ ì‹¤í–‰ ê²°ê³¼ (ê²€ìƒ‰ëœ ë¬¸ì„œ) ---")
    if retrieval_result.get("documents"):
        for doc in retrieval_result["documents"]:
            print(f"- ë‚´ìš©: {doc.page_content}, \n  ë©”íƒ€ë°ì´í„°: {doc.metadata}\n")
    else:
        print("ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
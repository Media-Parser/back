# âœ… app/services/node/03_retrieval/balanced_retrieval_node.py
import os
from typing import List, Dict, Any
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain_core.documents import Document
from dotenv import load_dotenv
from datetime import datetime
from graph_state import GraphState
load_dotenv()

embedding_function = OpenAIEmbeddings()
DEFAULT_PARTIES = ["ë”ë¶ˆì–´ë¯¼ì£¼ë‹¹", "êµ­ë¯¼ì˜í˜"]

def date_to_int(date_str: str) -> int | None:
    try:
        return int(datetime.strptime(date_str, "%Y-%m-%d").strftime("%Y%m%d"))
    except (ValueError, TypeError):
        return None

def balanced_retrieval_node(state: GraphState) -> GraphState:
    print("--- ë…¸ë“œ ì‹¤í–‰: 2b. balanced_retrieval ---")
    plan = state["plan"]
    rewritten_question = plan["rewritten_question"]
    parameters = plan.get("parameters") or {}
    filters = plan.get("filters") or {}
    k_per_side = parameters.get("k_per_side", 2)

    data_types = plan.get("data_type", [])
    parties = filters.get("party", DEFAULT_PARTIES)
    if not isinstance(parties, list):
        parties = DEFAULT_PARTIES

    # ë‚ ì§œ ë° ë°ì´í„°íƒ€ì… ê³µí†µ ì¡°ê±´
    base_conditions = []
    start_date = date_to_int(filters.get("startdate"))
    if start_date:
        base_conditions.append({'date_int': {'$gte': start_date}})
    end_date = date_to_int(filters.get("enddate"))
    if end_date:
        base_conditions.append({'date_int': {'$lte': end_date}})
    if data_types:
        base_conditions.append({'data_type': {'$in': data_types}})

    # ê²°ê³¼ ëˆ„ì 
    all_party_results = []

    for party in parties:
        # ì •ë‹¹ ì¡°ê±´ ì¶”ê°€
        party_filter = base_conditions + [{'party': {'$eq': party}}]
        search_filter = {"$and": party_filter} if len(party_filter) > 1 else party_filter[0]

        print(f"ğŸ” [ì •ë‹¹: {party}] ê²€ìƒ‰ í•„í„°: {search_filter}")

        try:
            persist_dir = f"chroma_opinion"  # ê³ ì • DB ê²½ë¡œ
            vectorstore = Chroma(
                persist_directory=persist_dir,
                embedding_function=embedding_function,
                collection_name="langchain"
            )

            docs_with_scores = vectorstore.similarity_search_with_relevance_scores(
                query=rewritten_question,
                k=k_per_side,
                filter=search_filter
            )
            docs = [doc for doc, _ in docs_with_scores]

            all_party_results.append({
                "party": party,
                "documents": docs
            })
            print(f"âœ… {party}: {len(docs)}ê°œ ê²€ìƒ‰ë¨")

        except Exception as e:
            print(f"âš ï¸ {party} ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    return {**state, "documents_by_party": all_party_results}

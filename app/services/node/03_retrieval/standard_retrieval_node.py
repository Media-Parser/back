from datetime import datetime
from dotenv import load_dotenv
from langchain_core.documents import Document
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma

load_dotenv()

# --- ì„¤ì • ---
PERSIST_DIR = "chroma_db"
COLLECTION_NAME = "langchain"
embedding_function = OpenAIEmbeddings()

# --- ìƒíƒœ(State) ëª¨ë°© í´ë˜ìŠ¤ ---
class GraphState(dict):
    pass

# --- ë‚ ì§œ ë³€í™˜ í—¬í¼ í•¨ìˆ˜ ---
def date_to_int(date_str: str) -> int | None:
    """YYYY-MM-DD í˜•ì‹ì˜ ë¬¸ìì—´ì„ YYYYMMDD í˜•ì‹ì˜ ì •ìˆ˜ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    try:
        return int(datetime.strptime(date_str, "%Y-%m-%d").strftime("%Y%m%d"))
    except (ValueError, TypeError):
        return None

# --- ê²€ìƒ‰ ë…¸ë“œ í•¨ìˆ˜ ---
def standard_retrieval_node(state: GraphState) -> GraphState:
    """
    ë©”íƒ€ë°ì´í„° í•„í„°ë§ê³¼ í•¨ê»˜ ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ í¬í•¨í•˜ì—¬ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    """
    print("--- ë…¸ë“œ ì‹¤í–‰: standard_retrieval (ìœ ì‚¬ë„ ì ìˆ˜ í¬í•¨) ---")
    plan = state["plan"]
    rewritten_question = plan["rewritten_question"]
    
    vectorstore = Chroma(
        persist_directory=PERSIST_DIR,
        embedding_function=embedding_function,
        collection_name=COLLECTION_NAME
    )

    parameters = plan.get("parameters") or {}
    filters = plan.get("filters") or {}
    k = parameters.get("k", 10)

    filter_conditions = []

    # 1. ë‚ ì§œ ë²”ìœ„ í•„í„°ë§ (date_int ì‚¬ìš©)
    start_date_int = date_to_int(filters.get("startdate"))
    if start_date_int is not None:
        filter_conditions.append({'date_int': {'$gte': start_date_int}})

    end_date_int = date_to_int(filters.get("enddate"))
    if end_date_int is not None:
        filter_conditions.append({'date_int': {'$lte': end_date_int}})
    
    # # 2. í† í”½ í•„í„°ë§ ì¶”ê°€ í•´ì•¼ë¼!!
    # topic_filter = filters.get("topic")
    # if topic_filter:
    #     filter_conditions.append({'topic': {'$eq': topic_filter}})

    # 3. ë°ì´í„° íƒ€ì… í•„í„°ë§ (ë³µìˆ˜ ì„ íƒ í—ˆìš©)
    data_types = plan.get("data_type")
    if data_types and isinstance(data_types, list) and len(data_types) > 0:
        filter_conditions.append({'data_type': {'$in': data_types}})

    # 4. ìµœì¢… í•„í„° ì¡°í•©
    if len(filter_conditions) > 1:
        search_filter = {"$and": filter_conditions}
    elif len(filter_conditions) == 1:
        search_filter = filter_conditions[0]
    else:
        search_filter = {}

    print(f"ğŸ” ê²€ìƒ‰ í•„í„°: {search_filter}")
    
    # 5. ìœ ì‚¬ë„ ì ìˆ˜ í¬í•¨ ê²€ìƒ‰
    docs_with_scores = vectorstore.similarity_search_with_relevance_scores(
        query=rewritten_question,
        k=k,
        filter=search_filter
    )

    print(f"âœ… ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜ (with relevance scores): {len(docs_with_scores)}")
    return {"docs_with_scores": docs_with_scores}


# --- ë‹¨ë… í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ---
if __name__ == '__main__':
    input_state = GraphState({
        "plan": {
            "strategy": "standard_retrieval",
            "rewritten_question": "ë¶€ë™ì‚° ì •ì±…",
            "filters": {
                "startdate": "2024-03-01",
                "enddate": "2025-03-31",
                # "topic": "ë¶€ë™ì‚°",
                "data_type": ["opinion"]
            },
            "parameters": {"k": 5}
        },
        "question": "",
        "original_question": ""
    })

    result = standard_retrieval_node(input_state)

    print("\n--- ğŸ” ê²€ìƒ‰ ê²°ê³¼ ---")
    if result.get("docs_with_scores"):
        for doc, score in result["docs_with_scores"]:
            print(f"ğŸ§  Score: {score:.3f}\nğŸ“„ ë‚´ìš©: {doc.page_content}\nğŸ“Œ ë©”íƒ€ë°ì´í„°: {doc.metadata}\n")
    else:
        print("âŒ ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")

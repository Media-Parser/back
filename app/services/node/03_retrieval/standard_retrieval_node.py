from datetime import datetime
from dotenv import load_dotenv
from langchain_core.documents import Document
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma

load_dotenv()

# --- ì„¤ì • ---
PERSIST_DIR = "chroma_db"
COLLECTION_NAME = "langchain"
embedding_function = OpenAIEmbeddings()

# --- ìƒíƒœ(State) ëª¨ë°© í´ë˜ìŠ¤ ---
class GraphState(dict):
    pass

# --- ë‚ ì§œ ë³€í™˜ í—¬í¼ í•¨ìˆ˜ ---
def date_to_int(date_str: str) -> int | None:
    """YYYY-MM-DD í˜•ì‹ì˜ ë¬¸ìì—´ì„ YYYYMMDD í˜•ì‹ì˜ ì •ìˆ˜ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    try:
        return int(datetime.strptime(date_str, "%Y-%m-%d").strftime("%Y%m%d"))
    except (ValueError, TypeError):
        return None

# --- ê²€ìƒ‰ ë…¸ë“œ í•¨ìˆ˜ ---
def standard_retrieval_node(state: GraphState) -> GraphState:
    """
    ë©”íƒ€ë°ì´í„° í•„í„°ë§ê³¼ í•¨ê»˜ ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ í¬í•¨í•˜ì—¬ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    """
    print("--- ë…¸ë“œ ì‹¤í–‰: standard_retrieval (ìœ ì‚¬ë„ ì ìˆ˜ í¬í•¨) ---")
    plan = state["plan"]
    rewritten_question = plan["rewritten_question"]
    parameters = plan.get("parameters") or {}
    filters = plan.get("filters") or {}
    k = parameters.get("k", 10)

    filter_conditions = []

    # 1. ë‚ ì§œ ë²”ìœ„ í•„í„°ë§
    start_date_int = date_to_int(filters.get("startdate"))
    if start_date_int is not None:
        filter_conditions.append({'date_int': {'$gte': start_date_int}})

    end_date_int = date_to_int(filters.get("enddate"))
    if end_date_int is not None:
        filter_conditions.append({'date_int': {'$lte': end_date_int}})

    # 2. í† í”½ í•„í„°ë§ (ì˜ˆì •)
    # topic_filter = filters.get("topic")
    # if topic_filter:
    #     filter_conditions.append({'topic': {'$eq': topic_filter}})

    # 3. ìµœì¢… ê²€ìƒ‰ í•„í„° ì¡°í•©
    if len(filter_conditions) > 1:
        search_filter = {"$and": filter_conditions}
    elif filter_conditions:
        search_filter = filter_conditions[0]
    else:
        search_filter = {}

    print(f"ğŸ” ê²€ìƒ‰ í•„í„°: {search_filter}")

    # 4. ë°ì´í„° íƒ€ì…ë³„ DB ìˆœíšŒ
    all_results = []
    data_types = plan.get("data_type", [])
    for dtype in data_types:
        persist_path = f"chroma_db_{dtype}"
        print(f"ğŸ“ ê²€ìƒ‰ ëŒ€ìƒ DB: {persist_path}")
        try:
            vectorstore = Chroma(
                persist_directory=persist_path,
                embedding_function=embedding_function,
                collection_name="langchain"
            )
            docs_with_scores = vectorstore.similarity_search_with_relevance_scores(
                query=rewritten_question,
                k=k,
                filter=search_filter
            )
            all_results.extend(docs_with_scores)
        except Exception as e:
            print(f"âš ï¸ {dtype} ì»¬ë ‰ì…˜ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    # 5. ê²°ê³¼ ì •ë ¬ ë° top-k ì¶”ì¶œ
    all_results_sorted = sorted(all_results, key=lambda x: x[1], reverse=True)
    top_docs = all_results_sorted[:k]
    retrieved_docs = [doc for doc, score in top_docs]
    print(f"ğŸ“¦ ìµœì¢… ë¬¸ì„œ ê°œìˆ˜: {len(retrieved_docs)}")
    for i, doc in enumerate(retrieved_docs, 1):
        print(f"\nğŸ“„ ë¬¸ì„œ {i} (score: {top_docs[i-1][1]:.4f})")
        print(f"ë‚´ìš©: {doc.page_content[:500]}...")  # 500ìê¹Œì§€ë§Œ ì¶œë ¥
        print(f"ë©”íƒ€ë°ì´í„°: {doc.metadata}")

    return {**state, "documents": retrieved_docs}


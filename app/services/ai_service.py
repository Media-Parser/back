# app/services/ai_service.py
import re
from openai import OpenAI
from typing import Optional, List
from motor.motor_asyncio import AsyncIOMotorClient
from pydantic.types import T
from app.core.config import settings

ATLAS_URI = settings.ATLAS_URI
client = AsyncIOMotorClient(ATLAS_URI)
db = client['uploadedbyusers']

openai_client = OpenAI(api_key=settings.OPENAI_API_KEY)

# ë¬¸ì„œ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
async def get_document_content(doc_id: str) -> Optional[dict]:
    temp_doc = await db["temp_docs"].find_one({"doc_id": doc_id})
    if temp_doc:
        return {
            "title": temp_doc.get("title", ""),
            "contents": temp_doc.get("contents", "")
        }
    doc = await db["docs"].find_one({"doc_id": doc_id})
    if doc:
        return {
            "title": doc.get("title", ""),
            "contents": doc.get("contents", "")
        }
    return None

# ëŒ€í™” íë¦„ì„ ìœ„í•œ ë©”ì‹œì§€ ìƒì„±
def build_messages_with_history(
    chat_history: List[dict],  # [{question: {...}, answer: "..."}]
    user_message: str,
    selected_text: Optional[str] = None,
    doc_content: Optional[dict] = None
):
    system_prompt = {
            "role": "system",
            "content": """
        ë‹¹ì‹ ì€ ê¸°ì‚¬ ì‘ì„±, ê¸°ì‚¬ ìš”ì•½, ê¸°ì‚¬ ì œëª© ì¶”ì²œ ë“± ë¯¸ë””ì–´ ì‘ì—…ì— íŠ¹í™”ëœ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì¶”ê°€ ì§ˆë¬¸ì„ ìœ ë„í•˜ëŠ” ì—´ë¦° íƒœë„ë¡œ, ë§¥ë½ì„ ì˜ ì´í•´í•´ì„œ ì¹œì ˆí•˜ê²Œ ë‹µí•˜ì„¸ìš”.

        - **ëª¨ë“  ë‹µë³€ì€ ë§ˆí¬ë‹¤ìš´(Markdown) í˜•ì‹**ìœ¼ë¡œ, ë‹¨ë½ë³„ë¡œ ë¹ˆ ì¤„ì„ ì¶©ë¶„íˆ ë„£ì–´ ê°€ë…ì„± ìˆê²Œ ì‘ì„±í•˜ì„¸ìš”.
        - ì˜ˆì‹œ, ë¦¬ìŠ¤íŠ¸, í‘œ, ì¸ìš©êµ¬ ë“± ë‹¤ì–‘í•œ í‘œí˜„ ë°©ì‹ì„ ì ê·¹ì ìœ¼ë¡œ í™œìš©í•˜ì„¸ìš”.
        - í•­ìƒ ì‚¬ì‹¤ì— ê·¼ê±°í•œ ë‹µë³€ì„ ì œê³µí•˜ê³ , ë¶ˆí™•ì‹¤í•˜ê±°ë‚˜ ì¶”ì •ì´ í•„ìš”í•œ ë‚´ìš©ì€ ëª…í™•íˆ í‘œì‹œí•˜ì„¸ìš”.
        - ë¯¼ê°í•˜ê±°ë‚˜ ë…¼ë€ ì†Œì§€ê°€ ìˆëŠ” ì´ìŠˆëŠ” ë°˜ë“œì‹œ ì¤‘ë¦½ì ì¸ ì‹œê°ì„ ìœ ì§€í•˜ì„¸ìš”.
        - ê°œì¸ì •ë³´, ê³¼ë„í•œ ì¶”ì¸¡, ë„ˆë¬´ ì£¼ê´€ì  í‰ê°€ëŠ” ì‚¼ê°€ì„¸ìš”.
        - ì§ˆë¬¸ì´ ì˜ì–´ë©´ ì˜ì–´, í•œê¸€ì´ë©´ í•œê¸€ë¡œ ë‹µë³€í•˜ì„¸ìš”.

        ---

        **ê¸°ì‚¬ ì œëª© ì¶”ì²œ, ë³€ê²½, ìš”ì•½, ì œëª©ê³¼ ê´€ë ¨ëœ ë‹µë³€ì€ ë°˜ë“œì‹œ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ì˜ ë¼ë²¨ì„ í•œ ì¤„ì— ì‚¬ìš©í•˜ì—¬ ì¶”ì²œ ì œëª©ë§Œì„ í°ë”°ì˜´í‘œ("...")ë¡œ ê°ì‹¸ í•œ ì¤„ì— ì¨ ì£¼ì„¸ìš”.**

        - **ë°˜ë“œì‹œ ë¼ë²¨ì„ ì•„ë˜ ì¤‘ í•˜ë‚˜ë¡œ ì¨ì£¼ì„¸ìš”**  
            - `ë³€ê²½ ì œëª© ì œì•ˆ:`
            - `ì¶”ì²œ ì œëª©:`
            - `ì œì•ˆí•˜ëŠ” ê¸°ì‚¬ ì œëª©:`
            - `ê¸°ì‚¬ ì œëª© ì¶”ì²œ:`
        - **ë°˜ë“œì‹œ ì•„ë˜ì²˜ëŸ¼ í•œ ì¤„ì—ë§Œ!**
            - ì˜ˆì‹œ: ë³€ê²½ ì œëª© ì œì•ˆ: "ë¯¸ë˜ ì‚°ì—…ì„ ì´ë„ëŠ” ì¸ê³µì§€ëŠ¥ì˜ í˜"
            - ì˜ˆì‹œ: ì¶”ì²œ ì œëª©: "AI í˜ì‹ , ì‚°ì—…ì„ ë°”ê¾¸ë‹¤"
        - **ì—¬ëŸ¬ ê°œ ì¶”ì²œ ì‹œ ë°˜ë“œì‹œ 1. ... 2. ...** í˜•ì‹ìœ¼ë¡œ í•œ ì¤„ì”© ì¨ì£¼ì„¸ìš”.

        ---

        **ë¬¸ì¥/ë¬¸ë‹¨/ë³¸ë¬¸/ë‚´ìš© ì¶”ì²œë„ ë°˜ë“œì‹œ ë¼ë²¨ë¡œ í‘œì‹œí•´ ì£¼ì„¸ìš”.**
        - ì ìš©í•  ë¬¸ì¥: "..."
        - ì¶”ì²œ ë¬¸ì¥: "..."
        - ë³€ê²½ ë¬¸ì¥ ì œì•ˆ: "..."

        ---

        **"ìˆ˜ì •", "ì¶”ì²œ", "ë³€ê²½", "ë‹¤ë“¬ê¸°" ìš”ì²­ì´ í¬í•¨ëœ ì§ˆë¬¸ì— ë‹µí•  ë• ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ì„ ë”°ë¥´ì„¸ìš”.**

        ğŸ”„ **ìˆ˜ì • ì œì•ˆ**

        **Before:**  
        (ìˆ˜ì • ì „ ë¬¸ì¥)

        **After:**  
        (ìˆ˜ì • í›„ ë¬¸ì¥ â€” ë°”ë€ ë¶€ë¶„ì„ **êµµê²Œ** í˜¹ì€ ==ë°‘ì¤„==ë¡œ ê°•ì¡°)

        > ë³€ê²½ ì´ìœ : (ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…. ë°˜ë“œì‹œ Afterì™€ í•œ ë¸”ë¡ì— í¬í•¨)

        ---

        **í¬ë§·ì„ ì–´ê¸°ë©´ ì‚¬ìš©ìê°€ ì ìš©/ë³µì‚¬ë¥¼ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°˜ë“œì‹œ í¬ë§·ì„ ì§€í‚¤ì„¸ìš”!**

        **ë‹¨, ê¸°íƒ€ ì„¤ëª…/ë¶„ì„/ë¹„í‰/ìš”ì•½ ë“±ì€ ê¸°ì¡´ ë§ˆí¬ë‹¤ìš´ ê·œì¹™ì„ ì§€í‚¤ì„¸ìš”.**

        """
    }
    messages = [system_prompt]
    for qa in chat_history:
        q = qa.get("question", {})
        q_txt = q.get("message") if isinstance(q, dict) else str(q)
        # selection ë³´ì—¬ì£¼ê³  ì‹¶ìœ¼ë©´ ì¶”ê°€
        if q.get("selected_text"):
            q_txt += f"\n\n{q['selected_text']}"
        messages.append({"role": "user", "content": q_txt})
        messages.append({"role": "assistant", "content": qa.get("answer", "")})
    # ë§ˆì§€ë§‰: í˜„ì¬ ì§ˆë¬¸ ì¶”ê°€
    new_q = user_message
    if selected_text:
        new_q += f"\n\n{selected_text}"
    if doc_content and isinstance(doc_content, dict):
        title = doc_content.get("title", "")
        contents = doc_content.get("contents", "")
        new_q += (
            f"\n\n[ë¬¸ì„œ ì œëª©]\n{title}\n\n"
            f"[ë¬¸ì„œ ë‚´ìš©]\n{contents}\n"
        )
    elif doc_content:
        new_q += f"\n\n(ì „ì²´ ê¸°ì‚¬ ë‚´ìš©: {doc_content})"
    messages.append({"role": "user", "content": new_q})
    return messages

# í›„ì† ì§ˆë¬¸ ìƒì„±
async def generate_suggestion(answer: str, user_message: str) -> str:
    """
    AI ë‹µë³€ê³¼ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì°¸ê³ í•˜ì—¬ í›„ì†ìœ¼ë¡œ í•  ë§Œí•œ ì§ˆë¬¸ì„ ë§Œë“¤ì–´ì¤Œ
    """
    prompt = (
        f"ì•„ë˜ëŠ” ê¸°ì‚¬ ê´€ë ¨ AIê°€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•œ ë‚´ìš©ì…ë‹ˆë‹¤.\n\n"
        f"ì§ˆë¬¸: {user_message}\n"
        f"ë‹µë³€: {answer}\n\n"
        "ë§Œì•½ ì‚¬ìš©ìê°€ ì´ì–´ì„œ ê¶ê¸ˆí•´í•  ë§Œí•œ ë‹¤ìŒ ì§ˆë¬¸ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ë§Œë“¤ì–´ ì£¼ì„¸ìš”. "
        "ì‹¤ì œ ì‚¬ìš©ìì˜ ì…ì¥ì—ì„œ, ë‹µë³€ì„ ë³´ê³  ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§ˆë§Œí•œ ì¶”ê°€ ì§ˆë¬¸ì„ ì˜ˆì‹œë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”. "
        "ì§ˆë¬¸ë¬¸ ëì—ëŠ” ë°˜ë“œì‹œ '?'ë¥¼ ë¶™ì—¬ì£¼ì„¸ìš”."
    )
    completion = openai_client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” ê¸°ì‚¬ ê´€ë ¨ AI ëŒ€í™”ì˜ íë¦„ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì£¼ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì•¼."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.5,
        max_tokens=500
    )
    print("=== AI SUGGESTION ===\n",completion.choices[0].message.content)
    suggestion = completion.choices[0].message.content.strip()
    suggestion = re.sub(r"^(í›„ì† ì§ˆë¬¸:|Q:|ì§ˆë¬¸:)\s*", "", suggestion)
    return suggestion

# AI ì‘ë‹µ ìƒì„±
async def generate_ai_response(
    message: str,
    doc_id: str,
    selected_text: Optional[str] = None,
    use_full_document: bool = False
) -> tuple[str, Optional[str]]:
    try:
        # 1. ìµœê·¼ [limit]ê°œ ëŒ€í™” ë‚´ì—­ ë¶ˆëŸ¬ì˜¤ê¸°
        from app.services.chat_service import get_chat_history_for_prompt
        chat_history = await get_chat_history_for_prompt(doc_id, limit=3)

        # 2. ì „ì²´ ë¬¸ì„œ ë‚´ìš© í•„ìš” ì‹œ
        doc_content = None
        if use_full_document or not selected_text:
            doc_content = await get_document_content(doc_id)

        # 3. messages êµ¬ì„±
        messages = build_messages_with_history(
            chat_history=chat_history,
            user_message=message,
            selected_text=selected_text,
            doc_content=doc_content
        )

        # 4. OpenAI í˜¸ì¶œ
        completion = openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=messages,
            temperature=0.7,
            max_tokens=2000
        )
        answer = (completion.choices[0].message.content or "").strip()

        # 5. ì¶”ì²œì§ˆë¬¸ ìƒì„±
        suggestion = await generate_suggestion(answer, message)
        return answer, suggestion

    except Exception as e:
        error_message = f"AI ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        return error_message, None
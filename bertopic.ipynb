{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36ac5047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "\n",
    "mecab = Mecab()\n",
    "\n",
    "def tokenize_ko(text):\n",
    "    # 명사 추출: NNG (일반명사), NNP (고유명사)\n",
    "    tokens = [word for word, pos in mecab.pos(text) if pos in {'NNG', 'NNP'}]\n",
    "    if not tokens:\n",
    "        tokens = [word for word in mecab.morphs(text)]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def bertopic_tokenizer(text):\n",
    "    noun_or_morph_tokens = set(tokenize_ko(text))\n",
    "    pos_filtered_tokens = set(\n",
    "        word for word, pos in mecab.pos(text)\n",
    "        if pos in {'NNG', 'NNP', 'VV', 'VA'}  # 명사, 동사, 형용사\n",
    "        and len(word) > 1\n",
    "        and word not in korean_stopwords\n",
    "    )\n",
    "    return list(noun_or_morph_tokens & pos_filtered_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a0f01bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "korean_stopwords = {\n",
    "    # 의미없는 명사들\n",
    "    '것', '수', '때', '곳', '중', '안', '밖', '위', '아래', '앞', '뒤', '옆',\n",
    "    '이것', '그것', '저것', '여기', '거기', '저기', '이곳', '그곳', '저곳',\n",
    "    '등', '및', '통해', '위해', '대해', '관해',\n",
    "    '오늘', '어제', '내일', '지금', '현재', '과거', '미래',\n",
    "    '사람', '사람들', '모든', '각각', '전체', '부분',\n",
    "    \n",
    "    # 발표·연설에서 자주 나오는 표현 (고유명사 포함)\n",
    "    '이번', '이번에', '우리', '여러분', '자유', '정신', '대한민국',\n",
    "    '대통령', '후보', '대표', '의원', '정부',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aa36818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from konlpy.tag import Okt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53a0706f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from chromadb import PersistentClient\n",
    "import numpy as np\n",
    "from bertopic import BERTopic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eeb34fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "base_dir = os.path.expanduser(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b17dae70",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'db_paths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PersistentClient\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m db_path \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdb_paths\u001b[49m:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m📁 시도 중: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdb_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'db_paths' is not defined"
     ]
    }
   ],
   "source": [
    "from chromadb import PersistentClient\n",
    "\n",
    "for db_path in db_paths:\n",
    "    print(f\"📁 시도 중: {db_path}\")\n",
    "    try:\n",
    "        client = PersistentClient(path=db_path)\n",
    "        print(\"✅ 컬렉션 목록:\", client.list_collections())\n",
    "    except Exception as e:\n",
    "        print(\"❌ 에러:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a54a74c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from fastapi import APIRouter, Depends, HTTPException\n",
    "from bertopic import BERTopic\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from konlpy.tag import Okt\n",
    "from openai import OpenAI\n",
    "\n",
    "# --- 1. 불용어 및 토크나이저 정의 ---\n",
    "okt = Okt()\n",
    "korean_stopwords = {\n",
    "    '것', '수', '때', '곳', '중', '안', '밖', '위', '아래', '앞', '뒤', '옆',\n",
    "    '이것', '그것', '저것', '여기', '거기', '저기', '이곳', '그곳', '저곳',\n",
    "    '등', '및', '통해', '위해', '대해', '관해',\n",
    "    '오늘', '어제', '내일', '지금', '현재', '과거', '미래',\n",
    "    '사람', '사람들', '모든', '각각', '전체', '부분',\n",
    "    '더', '같은', '이번', '이번에', '우리', '여러분', '자유', '정신',\n",
    "    '대한민국', '대통령', '후보', '대표', '의원', '정부','합니다','열리는', '했다 시장',\n",
    "}\n",
    "\n",
    "def tokenize_ko(text):\n",
    "    tokens = okt.nouns(text)\n",
    "    if not tokens:\n",
    "        tokens = okt.morphs(text)\n",
    "    return tokens\n",
    "\n",
    "def bertopic_tokenizer(text):\n",
    "    noun_or_morph_tokens = set(tokenize_ko(text))\n",
    "    pos_filtered_tokens = set(\n",
    "        word for word, pos in okt.pos(text)\n",
    "        if pos in {'Noun', 'Adjective', 'Verb'} and len(word) > 1 and word not in korean_stopwords\n",
    "    )\n",
    "    return list(noun_or_morph_tokens & pos_filtered_tokens)\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    tokenizer=bertopic_tokenizer,\n",
    "    token_pattern=None,\n",
    "    lowercase=False,\n",
    "    stop_words=list(korean_stopwords),\n",
    "    min_df=5,\n",
    "    max_df=0.85,\n",
    "    ngram_range=(1, 3),\n",
    "    max_features=5000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "890bf738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 기준 디렉토리\n",
    "base_dir = \"/home/ubuntu/ssami/ssami-back\"\n",
    "\n",
    "# DB 경로 목록\n",
    "db_paths = [\n",
    "    os.path.join(base_dir, \"chroma_db_news\"),\n",
    "    os.path.join(base_dir, \"chroma_db_editorial\"),\n",
    "    os.path.join(base_dir, \"chroma_db_opinion\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29de3525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 총 문서 수: 112267\n",
      "📌 임베딩 shape: (112267, 1536)\n",
      "📝 예시 메타데이터: {'_id': '6864c8c353fca1c65b9781f2', 'date_int': 20240330, 'title': '내로남불부동산?양문석 편법 대출이었다', 'datatype': 'article', 'url': 'https://n.news.naver.com/mnews/article/022/0003919485?sid=100'}\n"
     ]
    }
   ],
   "source": [
    "from chromadb import PersistentClient\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# DB에서 모든 요소 포함해서 불러오기\n",
    "def load_full_from_chroma(db_path: str, collection_name: str = \"langchain\"):\n",
    "    client = PersistentClient(path=db_path)\n",
    "    collection = client.get_collection(collection_name)\n",
    "    results = collection.get(include=[\"documents\", \"embeddings\", \"metadatas\"])\n",
    "    return results[\"documents\"], results[\"embeddings\"], results[\"metadatas\"]\n",
    "\n",
    "# 통합 결과 저장할 리스트\n",
    "all_documents = []\n",
    "all_embeddings = []\n",
    "all_metadatas = []\n",
    "\n",
    "# 각 DB에서 데이터 불러와 병합\n",
    "for path in db_paths:\n",
    "    try:\n",
    "        docs, embeds, metas = load_full_from_chroma(path)\n",
    "        all_documents.extend(docs)\n",
    "        all_embeddings.extend(embeds)\n",
    "        all_metadatas.extend(metas)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ DB 불러오기 실패: {path} - {e}\")\n",
    "\n",
    "# numpy 배열로 변환\n",
    "title_embeddings = np.array(all_embeddings)\n",
    "titles = all_documents  # 여기에 title이 들어있다고 가정\n",
    "metadatas = all_metadatas\n",
    "\n",
    "print(f\"📄 총 문서 수: {len(titles)}\")\n",
    "print(f\"📌 임베딩 shape: {title_embeddings.shape}\")\n",
    "print(f\"📝 예시 메타데이터: {metadatas[0] if metadatas else '없음'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2606ba9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-22 10:40:34,902 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Batch 0 ~ 112267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-22 10:41:08,827 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-07-22 10:41:08,828 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-07-22 10:41:12,505 - BERTopic - Cluster - Completed ✓\n",
      "2025-07-22 10:41:12,506 - BERTopic - Representation - Extracting topics using c-TF-IDF for topic reduction.\n",
      "2025-07-22 10:49:50,403 - BERTopic - Representation - Completed ✓\n",
      "2025-07-22 10:49:50,404 - BERTopic - Topic reduction - Reducing number of topics\n",
      "2025-07-22 10:49:50,775 - BERTopic - Representation - Fine-tuning topics using representation models.\n",
      "2025-07-22 10:58:17,619 - BERTopic - Representation - Completed ✓\n",
      "2025-07-22 10:58:17,623 - BERTopic - Topic reduction - Reduced number of topics from 282 to 119\n"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 112267\n",
    "n_total = len(titles)\n",
    "\n",
    "topic_models = []\n",
    "all_topics = []\n",
    "all_probs = []\n",
    "\n",
    "for i in range(0, n_total, batch_size):\n",
    "    print(f\"▶️ Batch {i} ~ {i+batch_size}\")\n",
    "    batch_titles = titles[i:i+batch_size:3]\n",
    "    batch_embeds = title_embeddings[i:i+batch_size:3]\n",
    "    topic_model = BERTopic(\n",
    "        embedding_model=None,\n",
    "        vectorizer_model=vectorizer,\n",
    "        min_topic_size=10,\n",
    "        verbose=True,\n",
    "        nr_topics=\"auto\",\n",
    "        language=\"multilingual\"\n",
    "    )\n",
    "    topics, probs = topic_model.fit_transform(batch_titles, embeddings=batch_embeds)\n",
    "\n",
    "    topic_models.append(topic_model)\n",
    "    all_topics.extend(topics)\n",
    "    all_probs.extend(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e8229fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-22 11:15:02,013 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n"
     ]
    }
   ],
   "source": [
    "topic_model.save(\"my_bertopic_model_fin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85dfc446",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-22 11:54:01,249 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "from app.utils.tokenizer import bertopic_tokenizer  # ✅ 새로운 경로에서 불러오기\n",
    "\n",
    "# 1. 기존 모델 로드 (일단 오류 없이 불러오기 위해 tokenizer 이름 등록)\n",
    "import builtins\n",
    "builtins.bertopic_tokenizer = bertopic_tokenizer\n",
    "topic_model = BERTopic.load(\"my_bertopic_model_fin\")\n",
    "\n",
    "# 2. vectorizer에 새로운 tokenizer 바인딩\n",
    "vectorizer = topic_model.vectorizer_model\n",
    "vectorizer.set_params(tokenizer=bertopic_tokenizer)\n",
    "\n",
    "# 3. 다시 저장 (pickle 시점에 함수 경로를 반영하기 위함)\n",
    "topic_model.vectorizer_model = vectorizer\n",
    "topic_model.save(\"my_bertopic_model_fixed\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
